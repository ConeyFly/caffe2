{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io\n",
    "from scipy.ndimage import zoom\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pre-processing, copy from caffe.io\n",
    "\n",
    "class Transformer:\n",
    "    \"\"\"\n",
    "    Transform input for feeding into a Net.\n",
    "\n",
    "    Note: this is mostly for illustrative purposes and it is likely better\n",
    "    to define your own input preprocessing routine for your needs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : a Net for which the input should be prepared\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.transpose = {}\n",
    "        self.channel_swap = {}\n",
    "        self.raw_scale = {}\n",
    "        self.mean = {}\n",
    "        self.input_scale = {}\n",
    "\n",
    "    def __check_input(self, in_):\n",
    "        if in_ not in self.inputs:\n",
    "            raise Exception('{} is not one of the net inputs: {}'.format(\n",
    "                in_, self.inputs))\n",
    "\n",
    "    def preprocess(self, in_, data):\n",
    "        \"\"\"\n",
    "        Format input for Caffe:\n",
    "        - convert to single\n",
    "        - resize to input dimensions (preserving number of channels)\n",
    "        - transpose dimensions to K x H x W\n",
    "        - reorder channels (for instance color to BGR)\n",
    "        - scale raw input (e.g. from [0, 1] to [0, 255] for ImageNet models)\n",
    "        - subtract mean\n",
    "        - scale feature\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_ : name of input blob to preprocess for\n",
    "        data : (H' x W' x K) ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        caffe_in : (K x H x W) ndarray for input to a Net\n",
    "        \"\"\"\n",
    "        self.__check_input(in_)\n",
    "        caffe_in = data.astype(np.float32, copy=False)\n",
    "        transpose = self.transpose.get(in_)\n",
    "        channel_swap = self.channel_swap.get(in_)\n",
    "        raw_scale = self.raw_scale.get(in_)\n",
    "        mean = self.mean.get(in_)\n",
    "        input_scale = self.input_scale.get(in_)\n",
    "        in_dims = self.inputs[in_][2:]\n",
    "        if caffe_in.shape[:2] != in_dims:\n",
    "            caffe_in = resize_image(caffe_in, in_dims)\n",
    "        if transpose is not None:\n",
    "            caffe_in = caffe_in.transpose(transpose)\n",
    "        if channel_swap is not None:\n",
    "            caffe_in = caffe_in[channel_swap, :, :]\n",
    "        if raw_scale is not None:\n",
    "            caffe_in *= raw_scale\n",
    "        if mean is not None:\n",
    "            caffe_in -= mean\n",
    "        if input_scale is not None:\n",
    "            caffe_in *= input_scale\n",
    "        return caffe_in\n",
    "\n",
    "    def deprocess(self, in_, data):\n",
    "        \"\"\"\n",
    "        Invert Caffe formatting; see preprocess().\n",
    "        \"\"\"\n",
    "        self.__check_input(in_)\n",
    "        decaf_in = data.copy().squeeze()\n",
    "        transpose = self.transpose.get(in_)\n",
    "        channel_swap = self.channel_swap.get(in_)\n",
    "        raw_scale = self.raw_scale.get(in_)\n",
    "        mean = self.mean.get(in_)\n",
    "        input_scale = self.input_scale.get(in_)\n",
    "        if input_scale is not None:\n",
    "            decaf_in /= input_scale\n",
    "        if mean is not None:\n",
    "            decaf_in += mean\n",
    "        if raw_scale is not None:\n",
    "            decaf_in /= raw_scale\n",
    "        if channel_swap is not None:\n",
    "            decaf_in = decaf_in[np.argsort(channel_swap), :, :]\n",
    "        if transpose is not None:\n",
    "            decaf_in = decaf_in.transpose(np.argsort(transpose))\n",
    "        return decaf_in\n",
    "\n",
    "    def set_transpose(self, in_, order):\n",
    "        \"\"\"\n",
    "        Set the input channel order for e.g. RGB to BGR conversion\n",
    "        as needed for the reference ImageNet model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_ : which input to assign this channel order\n",
    "        order : the order to transpose the dimensions\n",
    "        \"\"\"\n",
    "        self.__check_input(in_)\n",
    "        if len(order) != len(self.inputs[in_]) - 1:\n",
    "            raise Exception('Transpose order needs to have the same number of '\n",
    "                            'dimensions as the input.')\n",
    "        self.transpose[in_] = order\n",
    "\n",
    "    def set_channel_swap(self, in_, order):\n",
    "        \"\"\"\n",
    "        Set the input channel order for e.g. RGB to BGR conversion\n",
    "        as needed for the reference ImageNet model.\n",
    "        N.B. this assumes the channels are the first dimension AFTER transpose.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_ : which input to assign this channel order\n",
    "        order : the order to take the channels.\n",
    "            (2,1,0) maps RGB to BGR for example.\n",
    "        \"\"\"\n",
    "        self.__check_input(in_)\n",
    "        if len(order) != self.inputs[in_][1]:\n",
    "            raise Exception('Channel swap needs to have the same number of '\n",
    "                            'dimensions as the input channels.')\n",
    "        self.channel_swap[in_] = order\n",
    "\n",
    "    def set_raw_scale(self, in_, scale):\n",
    "        \"\"\"\n",
    "        Set the scale of raw features s.t. the input blob = input * scale.\n",
    "        While Python represents images in [0, 1], certain Caffe models\n",
    "        like CaffeNet and AlexNet represent images in [0, 255] so the raw_scale\n",
    "        of these models must be 255.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_ : which input to assign this scale factor\n",
    "        scale : scale coefficient\n",
    "        \"\"\"\n",
    "        self.__check_input(in_)\n",
    "        self.raw_scale[in_] = scale\n",
    "\n",
    "    def set_mean(self, in_, mean):\n",
    "        \"\"\"\n",
    "        Set the mean to subtract for centering the data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_ : which input to assign this mean.\n",
    "        mean : mean ndarray (input dimensional or broadcastable)\n",
    "        \"\"\"\n",
    "        self.__check_input(in_)\n",
    "        ms = mean.shape\n",
    "        if mean.ndim == 1:\n",
    "            # broadcast channels\n",
    "            if ms[0] != self.inputs[in_][1]:\n",
    "                raise ValueError('Mean channels incompatible with input.')\n",
    "            mean = mean[:, np.newaxis, np.newaxis]\n",
    "        else:\n",
    "            # elementwise mean\n",
    "            if len(ms) == 2:\n",
    "                ms = (1,) + ms\n",
    "            if len(ms) != 3:\n",
    "                raise ValueError('Mean shape invalid')\n",
    "            if ms != self.inputs[in_][1:]:\n",
    "                raise ValueError('Mean shape incompatible with input shape.')\n",
    "        self.mean[in_] = mean\n",
    "\n",
    "    def set_input_scale(self, in_, scale):\n",
    "        \"\"\"\n",
    "        Set the scale of preprocessed inputs s.t. the blob = blob * scale.\n",
    "        N.B. input_scale is done AFTER mean subtraction and other preprocessing\n",
    "        while raw_scale is done BEFORE.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_ : which input to assign this scale factor\n",
    "        scale : scale coefficient\n",
    "        \"\"\"\n",
    "        self.__check_input(in_)\n",
    "        self.input_scale[in_] = scale\n",
    "\n",
    "def resize_image(im, new_dims, interp_order=1):\n",
    "    \"\"\"\n",
    "    Resize an image array with interpolation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im : (H x W x K) ndarray\n",
    "    new_dims : (height, width) tuple of new dimensions.\n",
    "    interp_order : interpolation order, default is linear.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    im : resized ndarray with shape (new_dims[0], new_dims[1], K)\n",
    "    \"\"\"\n",
    "    if im.shape[-1] == 1 or im.shape[-1] == 3:\n",
    "        im_min, im_max = im.min(), im.max()\n",
    "        if im_max > im_min:\n",
    "            # skimage is fast but only understands {1,3} channel images\n",
    "            # in [0, 1].\n",
    "            im_std = (im - im_min) / (im_max - im_min)\n",
    "            resized_std = resize(im_std, new_dims, order=interp_order)\n",
    "            resized_im = resized_std * (im_max - im_min) + im_min\n",
    "        else:\n",
    "            # the image is a constant -- avoid divide by 0\n",
    "            ret = np.empty((new_dims[0], new_dims[1], im.shape[-1]),\n",
    "                           dtype=np.float32)\n",
    "            ret.fill(im_min)\n",
    "            return ret\n",
    "    else:\n",
    "        # ndimage interpolates anything but more slowly.\n",
    "        scale = tuple(np.array(new_dims, dtype=float) / np.array(im.shape[:2]))\n",
    "        resized_im = zoom(im, scale + (1,), order=interp_order)\n",
    "    return resized_im.astype(np.float32)\n",
    "\n",
    "## Image IO\n",
    "\n",
    "def load_image(filename, color=True):\n",
    "    \"\"\"\n",
    "    Load an image converting from grayscale or alpha as needed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "    color : boolean\n",
    "        flag for color format. True (default) loads as RGB while False\n",
    "        loads as intensity (if image is already grayscale).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image : an image with type np.float32 in range [0, 1]\n",
    "        of size (H x W x 3) in RGB or\n",
    "        of size (H x W x 1) in grayscale.\n",
    "    \"\"\"\n",
    "    img = skimage.img_as_float(skimage.io.imread(filename, as_grey=not color)).astype(np.float32)\n",
    "    if img.ndim == 2:\n",
    "        img = img[:, :, np.newaxis]\n",
    "        if color:\n",
    "            img = np.tile(img, (1, 1, 3))\n",
    "    elif img.shape[2] == 4:\n",
    "        img = img[:, :, :3]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = Transformer({'data': (1, 3, 300, 300)})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_mean('data', np.array([104,117,123])) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)\n",
    "transformer.set_channel_swap('data', (2,1,0))\n",
    "image_resize = 300\n",
    "\n",
    "#image = load_image('./cat.jpg')\n",
    "image = load_image('./2009_000898.jpg')\n",
    "\n",
    "transformed_image = transformer.preprocess('data', image)\n",
    "#print transformed_image\n",
    "np.save('transformed_image',transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python import workspace, core\n",
    "\n",
    "def deviceOpts(cpu_or_cuda):\n",
    "    device_opts = caffe2_pb2.DeviceOption()\n",
    "    if cpu_or_cuda == 'cpu':\n",
    "        device_opts.device_type = caffe2_pb2.CPU\n",
    "    elif cpu_or_cuda == 'cuda':\n",
    "        device_opts.device_type = caffe2_pb2.CUDA\n",
    "        device_opts.cuda_gpu_id = 0\n",
    "    return device_opts\n",
    "\n",
    "_devs = {'CUDA': deviceOpts('cuda'), 'CPU': deviceOpts('cpu')}\n",
    "\n",
    "def initNet(init_net_path):\n",
    "    init_def = caffe2_pb2.NetDef()\n",
    "    with open(init_net_path, 'r') as f:\n",
    "        init_def.ParseFromString(f.read())\n",
    "      #  init_def.device_option.CopyFrom(_devs['CPU'])\n",
    "        workspace.RunNetOnce(init_def)\n",
    "    return init_def\n",
    "        \n",
    "def createNet(predict_net_path):\n",
    "    net_def = caffe2_pb2.NetDef()\n",
    "    with open(predict_net_path, 'r') as f:\n",
    "        net_def.ParseFromString(f.read())\n",
    "#         for op in net_def.op:\n",
    "#             if op.type == 'PriorBox':\n",
    "#                 op.device_option.CopyFrom(_devs['CPU'])\n",
    "#             elif op.type == 'Concat' and op.output[0] == 'mbox_priorbox':\n",
    "#                 op.device_option.CopyFrom(_devs['CPU'])\n",
    "#             elif op.type == 'Norm':\n",
    "#                 op.device_option.CopyFrom(_devs['CPU'])\n",
    "#             elif op.type == 'DetectionOutput':\n",
    "#                 op.device_option.CopyFrom(_devs['CPU'])\n",
    "#             else:\n",
    "#                 op.device_option.CopyFrom(_devs['CPU'])\n",
    "#                 op.engine = 'CUDNN'\n",
    "    workspace.CreateNet(net_def, overwrite=True)\n",
    "    return net_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback for operator -823911416 in network \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at operator.cc:112] op. Cannot create operator of type 'GiveTensorFill' on the device 'CPU'. Verify that implementation for the corresponding device exist. It might also happen if the binary is not linked with the operator implementation code. If Python frontend is used it might happen if dyndep.InitOpsLibrary call is missing. Operator def: output: \"conv8_2_mbox_loc_flat\" name: \"\" type: \"GiveTensorFill\" arg { name: \"shape\" ints: 1 ints: 144 } arg { name: \"values\" floats: -0.30566519 floats: 2.802747 floats: -0.10947055 floats: 1.6106558 floats: -0.27195555 floats: -1.1798815 floats: 2.5605021 floats: -0.59167719 floats: 1.2624134 floats: 1.0258973 floats: 0.7600522 floats: -0.98398888 floats: 1.4630194 floats: 0.11375118 floats: 0.15173084 floats: 1.5104275 floats: 0.11258781 floats: 2.606189 floats: -1.6561379 floats: 3.0375993 floats: -0.72225285 floats: -0.51424956 floats: 2.489754 floats: 0.58756834 floats: 1.2453156 floats: 2.2452207 floats: -0.063578784 floats: -0.81164229 floats: 2.4767044 floats: 0.53782529 floats: 0.073128581 floats: 0.77306378 floats: 0.70773911 floats: 1.8789288 floats: -2.0335667 floats: 3.0820384 floats: -1.0655271 floats: 0.58321238 floats: 1.6981242 floats: 0.20346655 floats: 1.3519098 floats: 1.5520208 floats: -0.089008331 floats: 0.110863 floats: 1.6534436 floats: 0.56042641 floats: 0.20565976 floats: -0.23173654 floats: -0.36992204 floats: 3.0812755 floats: 0.7298913 floats: 1.5465639 floats: -2.0949624 floats: -0.32173043 floats: 2.2174408 floats: -1.3140168 floats: -0.63724452 floats: 0.89609766 floats: 1.67489 floats: -0.78597641 floats: 2.4451189 floats: 1.5768046 floats: 0.10358137 floats: 2.5733933 floats: -0.087880015 floats: 2.2902577 floats: -1.1764408 floats: 3.9821806 floats: -1.7065411 floats: -0.32940856 floats: 2.374404 floats: -0.46880412 floats: -1.1066403 floats: 1.5795517 floats: -0.0013735592 floats: -0.77897859 floats: 2.8444915 floats: 1.6244597 floats: -0.046150386 floats: 0.96857178 floats: 0.057532549 floats: 1.8839511 floats: -1.3863635 floats: 3.6050429 floats: -0.70056963 floats: 0.4212018 floats: 1.9421923 floats: -0.70516175 floats: 0.06004291 floats: 0.74874258 floats: -0.58572936 floats: 0.14272678 floats: 1.2985789 floats: 0.77917981 floats: 0.63252026 floats: 0.009493351 floats: -0.7267704 floats: 1.9558448 floats: 1.0302235 floats: 1.9206901 floats: -1.6517712 floats: 0.30847293 floats: 0.93991262 floats: -1.6941082 floats: -1.4112395 floats: 0.59329653 floats: 1.3124341 floats: 0.20484725 floats: 2.2107089 floats: 1.39163 floats: -0.76277983 floats: 1.6484607 floats: -0.50765038 floats: 1.5403078 floats: 0.24800675 floats: 3.2623289 floats: -0.68830705 floats: -0.3514744 floats: 1.2965765 floats: -1.1473755 floats: -1.688548 floats: 0.73135722 floats: -0.022747561 floats: 0.087765262 floats: 1.8858024 floats: 1.2114756 floats: -1.0890139 floats: 0.822927 floats: -0.80307829 floats: 1.2362757 floats: -0.16371454 floats: 2.2650881 floats: 0.17578214 floats: -0.016719043 floats: 1.0670187 floats: -0.84213161 floats: -0.49048668 floats: -0.079644106 floats: -0.58865893 floats: 0.5033251 floats: 0.7543847 floats: 0.52149838 floats: -0.069412112 floats: 0.38941658 } ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8b4008815228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minit_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./train_net.pb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./VGG_VOC0712_SSD_300x300_ft_iter_120000_deploy.pb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minit_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnet_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-df4bed3acd86>\u001b[0m in \u001b[0;36minitNet\u001b[0;34m(init_net_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minit_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;31m#  init_def.device_option.CopyFrom(_devs['CPU'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunNetOnce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minit_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ernie/caffe2/build/caffe2/python/workspace.pyc\u001b[0m in \u001b[0;36mRunNetOnce\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWorkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_failed_op_net_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mGetNetName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mStringifyProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     )\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ernie/caffe2/build/caffe2/python/workspace.pyc\u001b[0m in \u001b[0;36mCallWithExceptionIntercept\u001b[0;34m(func, op_id_fetcher, net_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at operator.cc:112] op. Cannot create operator of type 'GiveTensorFill' on the device 'CPU'. Verify that implementation for the corresponding device exist. It might also happen if the binary is not linked with the operator implementation code. If Python frontend is used it might happen if dyndep.InitOpsLibrary call is missing. Operator def: output: \"conv8_2_mbox_loc_flat\" name: \"\" type: \"GiveTensorFill\" arg { name: \"shape\" ints: 1 ints: 144 } arg { name: \"values\" floats: -0.30566519 floats: 2.802747 floats: -0.10947055 floats: 1.6106558 floats: -0.27195555 floats: -1.1798815 floats: 2.5605021 floats: -0.59167719 floats: 1.2624134 floats: 1.0258973 floats: 0.7600522 floats: -0.98398888 floats: 1.4630194 floats: 0.11375118 floats: 0.15173084 floats: 1.5104275 floats: 0.11258781 floats: 2.606189 floats: -1.6561379 floats: 3.0375993 floats: -0.72225285 floats: -0.51424956 floats: 2.489754 floats: 0.58756834 floats: 1.2453156 floats: 2.2452207 floats: -0.063578784 floats: -0.81164229 floats: 2.4767044 floats: 0.53782529 floats: 0.073128581 floats: 0.77306378 floats: 0.70773911 floats: 1.8789288 floats: -2.0335667 floats: 3.0820384 floats: -1.0655271 floats: 0.58321238 floats: 1.6981242 floats: 0.20346655 floats: 1.3519098 floats: 1.5520208 floats: -0.089008331 floats: 0.110863 floats: 1.6534436 floats: 0.56042641 floats: 0.20565976 floats: -0.23173654 floats: -0.36992204 floats: 3.0812755 floats: 0.7298913 floats: 1.5465639 floats: -2.0949624 floats: -0.32173043 floats: 2.2174408 floats: -1.3140168 floats: -0.63724452 floats: 0.89609766 floats: 1.67489 floats: -0.78597641 floats: 2.4451189 floats: 1.5768046 floats: 0.10358137 floats: 2.5733933 floats: -0.087880015 floats: 2.2902577 floats: -1.1764408 floats: 3.9821806 floats: -1.7065411 floats: -0.32940856 floats: 2.374404 floats: -0.46880412 floats: -1.1066403 floats: 1.5795517 floats: -0.0013735592 floats: -0.77897859 floats: 2.8444915 floats: 1.6244597 floats: -0.046150386 floats: 0.96857178 floats: 0.057532549 floats: 1.8839511 floats: -1.3863635 floats: 3.6050429 floats: -0.70056963 floats: 0.4212018 floats: 1.9421923 floats: -0.70516175 floats: 0.06004291 floats: 0.74874258 floats: -0.58572936 floats: 0.14272678 floats: 1.2985789 floats: 0.77917981 floats: 0.63252026 floats: 0.009493351 floats: -0.7267704 floats: 1.9558448 floats: 1.0302235 floats: 1.9206901 floats: -1.6517712 floats: 0.30847293 floats: 0.93991262 floats: -1.6941082 floats: -1.4112395 floats: 0.59329653 floats: 1.3124341 floats: 0.20484725 floats: 2.2107089 floats: 1.39163 floats: -0.76277983 floats: 1.6484607 floats: -0.50765038 floats: 1.5403078 floats: 0.24800675 floats: 3.2623289 floats: -0.68830705 floats: -0.3514744 floats: 1.2965765 floats: -1.1473755 floats: -1.688548 floats: 0.73135722 floats: -0.022747561 floats: 0.087765262 floats: 1.8858024 floats: 1.2114756 floats: -1.0890139 floats: 0.822927 floats: -0.80307829 floats: 1.2362757 floats: -0.16371454 floats: 2.2650881 floats: 0.17578214 floats: -0.016719043 floats: 1.0670187 floats: -0.84213161 floats: -0.49048668 floats: -0.079644106 floats: -0.58865893 floats: 0.5033251 floats: 0.7543847 floats: 0.52149838 floats: -0.069412112 floats: 0.38941658 } "
     ]
    }
   ],
   "source": [
    "init_net = './train_net.pb'\n",
    "pred_net = './VGG_VOC0712_SSD_300x300_ft_iter_120000_deploy.pb'\n",
    "init_def = initNet(init_net)\n",
    "net_def = createNet(pred_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspace.FeedBlob('data', transformed_image[np.newaxis, :, :, :], _devs['CUDA'])\n",
    "workspace.RunNet(net_def.name, 1)\n",
    "\n",
    "detections = workspace.FetchBlob('detection_out')\n",
    "print detections\n",
    "# Parse the outputs.\n",
    "det_label = detections[0,0,:,1]\n",
    "det_conf = detections[0,0,:,2]\n",
    "det_xmin = detections[0,0,:,3]\n",
    "det_ymin = detections[0,0,:,4]\n",
    "det_xmax = detections[0,0,:,5]\n",
    "det_ymax = detections[0,0,:,6]\n",
    "\n",
    "# Get detections with confidence higher than 0.6.\n",
    "top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.1]\n",
    "\n",
    "top_conf = det_conf[top_indices]\n",
    "top_label_indices = det_label[top_indices].tolist()\n",
    "top_xmin = det_xmin[top_indices]\n",
    "top_ymin = det_ymin[top_indices]\n",
    "top_xmax = det_xmax[top_indices]\n",
    "top_ymax = det_ymax[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
